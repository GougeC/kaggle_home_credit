{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is my data cleaning code I set up in Quick_and_Dirty.ipynb\n",
    "\n",
    "data = pd.read_csv('data/application_train.csv')\n",
    "test_data = pd.read_csv('data/application_test.csv')\n",
    "data.rename(columns={x:x.lower() for x in data.columns}, inplace=True)\n",
    "test_data.rename(columns={x:x.lower() for x in test_data.columns}, inplace=True)\n",
    "\n",
    "bureau_features = pd.read_csv('data/bureau_features.csv')\n",
    "bureau_features.drop('credit_types',axis = 1,inplace = True)\n",
    "bureau_ids = bureau_features['sk_id_curr'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['has_bureau_features'] = data['sk_id_curr'].apply(lambda x: 1 if x in bureau_ids else 0)\n",
    "data = data.join(bureau_features,how='left',on='sk_id_curr',rsuffix='X')\n",
    "data.drop('sk_id_currX',axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data['has_bureau_features'] = test_data['sk_id_curr'].apply(lambda x: 1 if x in bureau_ids else 0)\n",
    "\n",
    "test_data = test_data.join(bureau_features,how='left',on='sk_id_curr',rsuffix='X')\n",
    "test_data.drop('sk_id_currX',axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_columns = [x for x in data.columns if data[x].dtype == np.float64]\n",
    "float_columns_with_nulls =  [c for c in float_columns if pd.isnull(data[c].values).any()]\n",
    "categorical_columns = [x for x in data.columns if data[x].dtype == object]\n",
    "\n",
    "###Cleaning training data \n",
    "#adding a null category for each categorical column \n",
    "for col in categorical_columns:\n",
    "    data.loc[:,col] = data[col].apply(lambda x: x if not pd.isnull(x) else \"null\")\n",
    "    \n",
    "uniques = {col:data[col].unique() for col in categorical_columns}\n",
    "\n",
    "#imputing nans in float columns and adding an is_imputed column\n",
    "for col in float_columns_with_nulls:\n",
    "    null_col = col+'_is_imputed'\n",
    "    data[null_col] = data[col].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "    data.loc[:,col] = data[col].apply(lambda x: 0 if pd.isnull(x) else x )\n",
    "    \n",
    "#creating dummy columns for all the categorical columns\n",
    "for col in categorical_columns:\n",
    "    for cat in uniques[col]:\n",
    "        data[col+'_'+cat] = data[col].apply(lambda x: 1 if x == cat else 0)\n",
    "    data= data.drop(col, axis = 1)\n",
    "    \n",
    "### Cleaning test data    \n",
    "#adding a null category for each categorical column \n",
    "for col in categorical_columns:\n",
    "    test_data.loc[:,col] = test_data[col].apply(lambda x: x if not pd.isnull(x) else \"null\")\n",
    "    \n",
    "\n",
    "#imputing nans in float columns and adding an is_imputed column\n",
    "for col in float_columns_with_nulls:\n",
    "    null_col = col+'_is_imputed'\n",
    "    test_data[null_col] = test_data[col].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "    test_data.loc[:,col] = test_data[col].apply(lambda x: 0 if pd.isnull(x) else x )\n",
    "    \n",
    "#creating dummy columns for all the categorical columns\n",
    "for col in categorical_columns:\n",
    "    for cat in uniques[col]:\n",
    "        test_data[col+'_'+cat] = test_data[col].apply(lambda x: 1 if x == cat else 0)\n",
    "    test_data= test_data.drop(col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = data.drop(['target','sk_id_curr'],axis = 1), data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "\n",
    "booster = xgboost.XGBClassifier()\n",
    "\n",
    "grid = GridSearchCV(estimator = booster,\n",
    "                    param_grid = params, \n",
    "                    scoring = 'roc_auc',\n",
    "                    n_jobs = -1,\n",
    "                    cv = 5,\n",
    "                    verbose = 2)\n",
    "\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 1.0, 'gamma': 5, 'max_depth': 3, 'min_child_weight': 10}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('bestparams.json','w') as f:\n",
    "        json.dump(grid.best_params_,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "booster = xgboost.XGBClassifier(subsample = .5, \n",
    "                                n_estimators = 20000, \n",
    "                                learning_rate= .01, \n",
    "                                colsample_bytree = 1, \n",
    "                                gamma = 5, \n",
    "                                mid_child_weight = 10,\n",
    "                                max_depth = 3,\n",
    "                                n_jobs = -1,\n",
    "                                silent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=5, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, mid_child_weight=10, min_child_weight=1, missing=None,\n",
       "       n_estimators=20000, n_jobs=-1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=False,\n",
       "       subsample=0.5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booster.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75372191799207178"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = booster.predict_proba(X_val)[:,1]\n",
    "\n",
    "roc_auc_score(y_val, y_hat,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop('sk_id_curr',axis = 1)\n",
    "\n",
    "test_predictions = booster.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submissions/result{}.csv'.format(len(os.listdir('submissions'))), 'w') as f:\n",
    "    f.write('SK_ID_CURR,TARGET\\n')\n",
    "    for i,p in zip(test_data['sk_id_curr'].values, test_predictions):\n",
    "        f.write(\"{},{}\\n\".format(i,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result0.csv\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
